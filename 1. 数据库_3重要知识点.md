# 重要知识点

## 1. MySQL索引

![image-20220420171132891](appendix\1. 数据库_3重要知识点\image-20220420171132891.png)

自适应哈希索引：当它注意到某些索引值被使用的非常频繁时，会在内存中基于B-Tree所有之上再创建一个哈希索引。这是一个完全自动的内部行为，用户无法控制或配置

### 1.1 数据结构

#### 1.1.1 2-3树

2-3树时多路查找树，包含2和3两种节点，元素值左小右大，叶子节点都在统一层

- 2节点：（2-1）个元素，2个指针；要么有2个指针，要么没有指针

- 3节点：（3-1）个元素，3个指针；要么有3个指针，要么没有指针

**指针的意思是子树**



#### 1.1.2 B树

##### 1.1.2.1 定义

平衡的多路查找树，2-3树也是B树，将树中节点最大的指针的数目称为B树的阶，记作m

一棵m阶B树或为空树，或满足：


- 树中的每个节点至多有m棵子树，**即至多m-1个关键字**（**两棵子树指针夹着一个关键字**）

	例如3节点
	
	|      | 12   |      | 15   |      |
	| ---- | ---- | ---- | ---- | ---- |

- 若根节点不是叶子节点，则至少有两棵子树，即**至少一个关键字**

- **除根节点外的所有非叶子节点，至少有m/2（向上取整）棵子树，即至少含有m/2-1个关键字**（判断是否分裂的关键，是为了维护平衡）

- 非叶子节点的结构

  ![image-20220419144309029](appendix\1. 数据库_3重要知识点\image-20220419144309029.png)

- 所有的叶子节点出现在统一层次，**不带信息**（就像折半查找判断树中查找失败的节点）



##### 1.1.2.2 查找

和二叉排序树差不多

##### 1.1.2.3 插入（创建）

![image-20220419145546341](appendix\1. 数据库_3重要知识点\image-20220419145546341.png)

##### 1.1.2.4 删除

![image-20220419150026185](appendix\1. 数据库_3重要知识点\image-20220419150026185.png)

![image-20220419150239833](appendix\1. 数据库_3重要知识点\image-20220419150239833.png)



#### 1.1.3 B+ 树

##### 1.1.3.1 定义

B+树常用于数据库和操作系统搞得文件系统的用于查找的数据结构

B+树是B树的一种变形形式，B+树上的叶子结点存储关键字以及相应记录的地址，叶子结点以上各层作为索引使用。一棵m阶的B+树定义如下: 

(1)每个结点至多有m个子女； 

(2)除根结点外，每个结点至少有[m/2]个子女，根结点至少有两个子女； 

(3)有k个子女的结点必有k个关键字。 

![image-20220419152103653](appendix\1. 数据库_3重要知识点\image-20220419152103653.png)

##### 1.1.3.2 与B树的差别

（这里除法都是向上取整）

- B+树中，**具有n个关键字的节点只有n个孩子(指针、子树)个数**，即每个关键字对应一棵子树；

  B树中，**具有n个关键字的节点含有(n+1)棵子树**

- B+树中，每个结点(非根内部结点）关键字个数n的范围是**[m/2]≤n≤m (根结点1≤n≤m)**；

  B树中，每个结点（非根内部结点）关键字个数n的范围是**[m/2]-1≤n≤m-1(根结点∶1≤n≤m-1)** 

- B+树中，叶结点包含信息，所有**非叶结点仅起到索引作用**，非叶结点中的**每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址**。

  在B树中**每个关键字对应一个记录的存储地址**。

  > 记录、信息：代表数据库里存的值（value）
  >
  > 索引：指针（key）

- B+树中，**叶结点包含了全部关键字**，即在非叶结点中出现的关键字也会出现在叶结点中，而且**叶子结点的指针指向记录**;

  B树中，叶结点包含的关键字和其他结点包含的关键字是不重复的。

- B+树中，**有一个指针指向关键字最小的叶子结点，所有叶子结点链接成一个单链表**。



#### 1.1.4 哈希表

无序



### 1.2 MySQL索引详解

- 索引：**索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash。**索引的作用就相当于目录的作用。（查字典）

- 在MySQL中, 索引是在存储引擎层实现的。InnoDB 引擎都是使用 B+Tree 作为索引结构。**每个索引在InnoDB中对应一棵B+树**。

- 适用场景：数据量较大。（大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。）

- 使用如下命令创建索引：

	```sql
	ALTER TABLE `table_name` ADD [PRIMARY KEY| UNIQUE | INDEX index_name | FULLTEXT ]( `column` )
	```



#### 1.2.1 索引优缺点

##### 1.2.1.1 优点

- 加快数据检索速度

- 创建唯一性索引，可保证数据库表中的每一行数据的唯一性

  

##### 1.2.1.1 缺点

- 创建索引和维护索引都需要耗费许多时间，降低SQL执行效率
- 索引需要物理文件存储，消耗空间



#### 1.2.2 索引的底层数据结构

##### 1.2.2.1 Hash表

（key,value）,可以快速检索数据



**存在的问题：**

- 需要解决哈希冲突：链地址法、红黑树
- Hash索引**不支持范围和顺序查找**，因为**Hash是无序的**



##### 1.2.2.2 B树

B树，多路平衡查找树



**存在的问题：**

- B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了
- 存在回旋查找的问题，比如像查大于5的所有数，需要先查到5，再遍历其他大于5的数



##### 1.2.2.3 B+树

![image-20220419153815023](appendix\1. 数据库_3重要知识点\image-20220419153815023.png)



#### 1.2.3 索引类型

##### 1.2.3.1 主键索引

数据表的主键列使用的就是主键索引。在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在null值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。

![image-20220419154443832](appendix\1. 数据库_3重要知识点\image-20220419154443832.png)



##### 1.2.3.2 二级索引（辅助索引）

二级索引又称为辅助索引，是因为**二级索引的叶子节点存储的数据是主键**。也就是说，通过二级索引，可以**定位主键的位置**。

**唯一索引，普通索引，前缀索引等索引属于二级索引。**

- 唯一索引：数据不能重复，可以为NULL，可有多个。（目的：大部分时候都是为了该属性列的**数据的唯一性**，而不是为了查询效率）
- 普通索引：数据可以重复，可以为NULL，可有多个。（目的：快速查询数据）
- 前缀索引：只适用于字符串，对文本前几个字符创建索引。
- 全文索引：（目的：检索大文本数据中的关键字信息）

![image-20220419155025163](appendix\1. 数据库_3重要知识点\image-20220419155025163.png)



#### 1.2.4 聚集索引和非聚集索引

##### 1.2.4.1 聚集索引

聚集索引即**索引结构和数据**一起存放的索引。**主键索引属于聚集索引。**

在 MySQL 中，InnoDB 引擎的表的 `.ibd`文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个**非叶子节点存储索引**，**叶子节点存储索引和索引对应的数据**。



**优点：**

- 查询速度快。叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。

  

**缺点：**

- **依赖有序的数据**。因为 B+树是多路平衡树，如果索引的数据**不是有序的，那么就需要在插入时排序**，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢

- **更新代价大。**如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的**叶子节点还存放着数据，修改代价肯定是较大的**，所以对于主键索引来说，主键一般都是不可被修改的。

  

##### 1.2.4.2 非聚集索引

非聚集索引即**索引结构和数据分开存放的索引。二级索引属于非聚集索引。**

非聚集索引的**叶子节点并不一定存放数据的指针**，因为二级索引的叶子节点就存放的是**主键**，根据主键再回表查数据



**优点：**

- 更新代价小。因为叶子节点不存放数据

  

**缺点：**

- 非聚集碎银依赖于有序的数据

- **可能会二次查询（回表）**。当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。**非聚集索引不一定回表查询。**主键索引本身的 key 就是主键，查到返回就行了，不用回表。

  

**索引下推：**

一项索引优化功能，可以在非聚簇索引遍历过程中，**对索引中包含的字段先做判断**，**过滤**掉不符合条件的记录，减少回表次数。



##### 1.2.4.3 聚集索引和非聚集索引

自增主键使索引有序，查询效率高



![image-20220419160237312](appendix\1. 数据库_3重要知识点\image-20220419160237312.png)

#### 1.2.5 覆盖索引

如果一个**索引包含（或者说覆盖）所有需要查询的字段的值**，我们就称之为“覆盖索引”。覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需**回表查询**（主要指非聚簇索引）。



#### **1.2.6 联合索引**

使用表中的**多个字段创建索引**，就是 **联合索引**，也叫 **组合索引** 或 **复合索引**



##### 1.2.6.1 最左前缀匹配原则

在使用联合索引时，**MySQL** 会根据联合索引中的字段顺序，从**左到右**依次到**查询条件**中去匹配。如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询，如 **`>`**、**`<`**、**`between`** 和 **`以%开头的like查询`** 等条件，才会停止匹配。

所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据。





#### **1.2.7 创建索引注意事项**

- 选择合适字段创建索引。
  - **不为 NULL 的字段**
  - **被频繁查询的字段**
  - **被作为条件查询的字段** ：where
  - **频繁需要排序的字段**：索引本身就有序
  - **被经常频繁用于连接的字段**：外键
- **被频繁更新的字段应该慎重建立索引。**
- **尽可能的考虑建立联合索引而不是单列索引。**磁盘空间
- **注意避免冗余索引** 。功能冗余
- **考虑在字符串类型的字段上使用前缀索引代替普通索引。**





#### 1.2.8 使用索引建议 

- 对于**中到大型**表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引,对于大型的表，需要用到一种技术可以直接区分出需要查询的一组数据，例如可以使用分区技术
- 避免 **where 子句**中对字段施加**函数**，这会造成无法命中索引。
- 在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用**逻辑主键**，而不要使用业务主键。
- **删除长期未使用的索引**，不用的索引的存在会造成不必要的性能损耗。
- 在使用 limit offset 查询缓慢时，可以借助索引来提高性能





## 2. MySQL三大日志

MySQL日志：错误日志、查询日志、慢查询日志、**事务日志**（redolog 重做日志）、**二进制日志**（binlog 归档日志）、中继日志（relay log） 

![image-20220418142642796](appendix\1. 数据库_3重要知识点\image-20220418142642796.png)



### 2.1 redo log

redo log是InnoDB存储引擎独有的，让mysql有了崩溃恢复能力，比如MySQL实例挂了，重启时，InnoDB会使用redo log回复数据，保证数据的**持久性**。

![image-20220418143218901](appendix\1. 数据库_3重要知识点\image-20220418143218901.png)

#### 2.1.1 写入机制

1. mysql的数据以 `页` 为单位，每查询一条记录，会从硬盘把一 `页` 的数据加载出来，存入`Buffer Pool`中;

2. 后续的查询都是先从`Buffer Pool`中找，如果没有命中再去硬盘加载，减少硬盘的I/O开销；更新表数据的时候，也是如此，发现`Buffer Pool`中存在要更新的数据，就直接在`Buffer Pool`中更新；

3. 再把“在某个数据页上做了什么修改”记录(`redo log 记录`)到重做日志缓存中`redo log buffer`；

4. 从`redo log buffer`中刷盘到`redo log `文件中。

   ![image-20220418151431936](appendix\1. 数据库_3重要知识点\image-20220418151431936.png)



#### 2.1.2 刷盘时机

（写入机制的一部分内容）

理想情况下，事务一提交就会进行刷盘操作，但可以根据需求来调整策略



##### 2.1.2.1 概述

InnoDB为`redo log`提供三种策略：（对应参数`innodb_flush_log_at_trx_commit`）

- 0：事务提交不刷盘
- 1：事务提交刷盘（默认）
- 2：事务提交把`redo log buffer`内容写入`page cache`（系统的页缓存）

另外，InnoDB存储引擎有一个后台线程，每隔`1s`，就会把`redo log buffer`的内容写入到`page cache`，然后调用`fsync`刷盘。

![image-20220418152048847](appendix\1. 数据库_3重要知识点\image-20220418152048847.png)



##### 2.1.2.2 innodb_flush_log_at_trx_commit=0

如果MySQL挂了或者系统宕机，会有1秒数据的丢失

![image-20220418152622457](appendix\1. 数据库_3重要知识点\image-20220418152622457.png)

##### 2.1.2.3 innodb_flush_log_at_trx_commit=1

如果MySQL挂了或者系统宕机，不会有数据的丢失

![image-20220418152757324](appendix\1. 数据库_3重要知识点\image-20220418152757324.png)



##### 2.1.2.4 innodb_flush_log_at_trx_commit=2

如果MySQL挂了，不会有数据的丢失；

如果系统宕机，会有1秒数据的丢失

![image-20220418152908043](appendix\1. 数据库_3重要知识点\image-20220418152908043.png)



#### 2.1.3 日志文件组

##### 2.1.3.1 存在形式

硬盘上的`redo log `是以`日志文件组`形式存在，采用**环形数组**的方式存储

![image-20220418153304230](appendix\1. 数据库_3重要知识点\image-20220418153304230.png)

##### 2.1.3.2 重要属性

其有两个重要属性:

- wirte pos：指向当前记录的位置，一边写一边后移
- checkpoint：指向当前可以擦除的位置（不是已经擦除的位置），一边写一边后移

每次刷盘`redo log 记录`到`日志文件组`时，`write pos`会后移

每次从MySQL加载`日志文件组`进行恢复时，会清空`redo log 记录`，并把`checkpoint`后移

`write pos` 和 `checkpoint` 之间的还空着的部分可以用来写入新的 `redo log记录`。

![image-20220418153813668](appendix\1. 数据库_3重要知识点\image-20220418153813668.png)

如果`checkpoint`追上`write pos`，则日志文件组满了，MySQL需要清空一些`redo log 记录`，推进`checkpoint`

![image-20220418154010719](appendix\1. 数据库_3重要知识点\image-20220418154010719.png)

#### 2.1.4 一些问题

- 什么是刷盘

  把数据写入磁盘，写入`redo.log`就是在刷盘，写入数据库也是在刷盘

- 为什么要写到`redo log buffer`中？而不是直接写到`redo.log`（这个）中，再放入硬盘？

  说到底`redo log`日志也是写到磁盘中的，也是写文件，速度会有影响，所以需要缓存（`redo log buffer`）。  

- 写入`redo log`中`redo log buffe`r会清空吧

  应该是

- **为什么不把每次修改后的数据页直接刷盘（写入数据库），而要写入redo.log?不都是刷盘吗**

  1. 直接刷盘耗时，性价比低。数据页的大小是16KB，可能就修改了数据页的几byte数据，没必要把整个数据页刷盘；

  2. 数据页刷盘是随机写。因为数据页的存放位置在硬盘的随机位置，但如果写redo.log，一行记录就占几十byte，而且是顺序写，刷盘速度远远大于数据页刷盘，所以用redo.log也可以让数据库的并发能力更强。

     > - 每条`redo记录`组成：表空间号+数据页号+偏移量+修改数据长度+具体修改的数据
     >
     > - 内存的数据也在一定时机也会刷盘

- 一个没有提交事务的`redo log记录`，也可能会刷盘吗

  是的。因为在事务执行时，`redo log 记录`写入`redo log buffer`，这些`redo log 记录`会被后台线程进行刷盘。除了后台线程每秒的轮询操作，当`redo log buffer`的大小即将到达`innodb_log_buffer_size`的一半的时候，后台线程也会主动刷盘。

  

#### 2.1.5 部分概念

- fsync函数：同步内存中所有已修改的文件数据到储存设备。  

- page cache : 文件系统缓存（与数据库无关，是电脑自己的缓存）



### 2.2 binlog

`binlog`是逻辑日志，记录语句原始逻辑。类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据**一致性**。

`binlog`会记录所有涉及**更新数据**的逻辑操作，并且是顺序写。

![image-20220418160751091](appendix\1. 数据库_3重要知识点\image-20220418160751091.png)



#### 2.2.1 记录格式

##### 2.2.1.1 概述

`binlog` 日志有三种格式：（对应参数`binlog_format`）

- **statement**
- **row**
- **mixed**

以执行一条`update T set update_time=now() where id=1`的语句进行讲解

##### 2.2.1.2 statement

- 只记录`SQL`语句**原文逻辑语句**

![image-20220418160942567](appendix\1. 数据库_3重要知识点\image-20220418160942567.png)



##### 2.2.1.3 row

- 记录`SQL`语句**原文逻辑语句**；

  记录**操作的具体数据**

- 原因是为了解决“`update_time=now()`这里会获取当前系统时间，直接执行会导致与原库的**数据不一致**“的问题。

![image-20220418161210506](appendix\1. 数据库_3重要知识点\image-20220418161210506.png)



##### 2.2.1.4 mix

- 在statment和row中按需进行选择

  `MySQL`会判断这条`SQL`语句是否可能引起数据不一致，如果是，就用`row`格式，否则就用`statement`格式；

  从而优化执行速度并减少容量



#### 2.2.2 写入机制

1. 事务执行过程中，先把日志记录写到`binlog cache`

2. 事务提交的时候，再把`binlog cache`写到`binlog`文件中

   

#### 2.2.3 刷盘时机

（写入机制的一部分）

![image-20220418161914705](appendix\1. 数据库_3重要知识点\image-20220418161914705.png)

注意：

- `write`：指把日志写入到文件系统的`page cache`，并没有数据持久化到磁盘

- `fsync`：把数据持久化到磁盘

  

##### 2.2.3.1 概述

`write`和`fsync`的时机是可以控制的：（对应参数`sync_binlog`）

- 0：事务提交都只`write`，由系统自行判断什么时候执行`fsync`。（默认）
- 1：提交事务都会执行`fsync`，就如同 **redo log 日志刷盘流程** 一样。
- N：每次提交事务都`write`，但累积`N`个事务后才`fsync`。（N>1）



##### 2.2.3.2 sync_binlog=0

如果MySQL挂了，没有数据的丢失

如果系统宕机，有数据的丢失

![image-20220418162728024](appendix\1. 数据库_3重要知识点\image-20220418162728024.png)



##### 2.2.3.3 sync_binlog=1

如果MySQL挂了或系统宕机，没有数据的丢失



##### 2.2.3.4 sync_binlog=N

如果MySQL挂了，没有数据丢失

如果系统宕机，有N个事务的`binlog`丢失

![image-20220418163026801](appendix\1. 数据库_3重要知识点\image-20220418163026801.png)



#### 2.2.4 `redo log`的两阶段提交

##### 2.2.4.1 使用原因

由于`redo log`与`binlog`的写入时机不一样，可能会导致两份日志之间的**逻辑不一致**，从而导致**数据的不一致**。

解释：

`redo log`（重做日志）让`InnoDB`存储引擎拥有了崩溃恢复能力。

`binlog`（归档日志）保证了`MySQL`集群架构的数据一致性。

在执行更新语句过程，会记录`redo log`与`binlog`两块日志，以**基本的事务**为单位，`redo log`在事务执行过程中可以不断写入，而`binlog`只有在提交事务时才写入，所以`redo log`与`binlog`的写入时机不一样。

以下图为例：

![image-20220418164304718](appendix\1. 数据库_3重要知识点\image-20220418164304718.png)

由于`binlog`没写完就异常，这时候`binlog`里面没有对应的修改记录。因此，之后用`binlog`日志恢复数据时，就会少这一次更新，恢复出来的这一行`c`值是`0`，而原库因为`redo log`日志恢复，这一行`c`值是`1`，最终数据不一致。

![image-20220418164346475](appendix\1. 数据库_3重要知识点\image-20220418164346475.png)

为了解决两份日志之间的逻辑一致问题，`InnoDB`存储引擎使用**两阶段提交**方案。



##### 2.2.4.2 原理

将`redo log`的写入拆成了两个步骤`prepare`和`commit`，进行**两阶段提交**。

![image-20220418164626714](appendix\1. 数据库_3重要知识点\image-20220418164626714.png)



##### 2.2.4.3 发生异常分析

- 写入`binlog`时发生异常

  会回滚

  ![image-20220418164734308](appendix\1. 数据库_3重要知识点\image-20220418164734308.png)

- `redo log`设置`commit`阶段发生异常

  不会回滚，因为可以通过事务id找到对应的`binlog`，这是完整的

  ![image-20220418164749460](appendix\1. 数据库_3重要知识点\image-20220418164749460.png)



#### 2.2.5 一些问题

- 为什么需要`binlog cache`

  因为一个事务的`binlog`不能被拆开，无论这个事务多大，也要**确保一次性写入**，所以系统会给每个线程分配一个块内存作为`binlog cache`。可以通过`binlog_cache_size`参数控制单个线程 `binlog cache` 大小，如果存储内容超过了这个参数，就要暂存到磁盘（`Swap`）。

- `binlog`应该只在数据更新的时候记录，查询不会产生`binlog`



### 2.3 undo log

`undo log`是为了保证事务的**原子性**，在异常发生的时候，对已经执行的操作进行回滚。

`undo log`相当于逻辑日志, 记录的是变化过程, 比如做一个删除`delete`, `undo log`记录`insert`, 反言之, 做`insert`操作, `undo log`记录`delete`, 这样在出问题时, 就可以直接运行`undo log`回滚到起始位置。



#### 2.3.1 概述

`undo log`产生时间：`undo log`在事务开始前产生;

`undo log`销毁时间：事务在提交后, 并不会立刻删除`undolog`, 因为这个过程中可能需要用到undolog, 比如MVCC多版本控制。InnoDB会将该事务对应的`undolog`入到`删除列表`中, 后面会通过**后台线程`purge thread`**进行回收处理。

`undo log`存储: `undo log`采用**段方式管理**和记录, 在InnoDB数据文件中包含一种`rollback segment`回滚段, 内部包含1024个`undolog segment`。



#### 2.3.2 作用

- 把所有没有`COMMIT`的事务回滚到事务开始之前的状态

- `rollback`

- 多版本并发控制(`MVCC`)：事务未提交前, `undo log`保存了**未提交前的版本数据**，`undo log`中数据可作为数据旧版本快照供其他并发事务进行快照读

  ![image-20220418165939625](appendix\1. 数据库_3重要知识点\image-20220418165939625.png)

  

  事务A手动开启事务, 执行更新, 首先会把更新命中的数据备份到`undo buffer`中

  在事务A还没有提交的时候，事务B手动开启事务, 执行查询操作, 会读取`undo log`日志数据返回, 进行快照读



#### 2.3.3 刷盘时机

回滚日志会**先于数据持久化到磁盘上**。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。



### 2.4 总结

- `redo log`：记录的是**结果**，属于数据库

  `binlog`：记录的是**逻辑**，控制语句，属于MySQL Server层

  `undo log`：记录的也是逻辑       

- `binlog`应该只在数据更新的时候记录，查询不会产生`binlog`

- `redo log`保证事务的持久性

  `undo log`保证事务的原子性

  MySQL数据库的数据备份、主备、主主、主从离不开`binlog`，保证数据的一致性

- bin log 和 redo log区别

  1.层次不同：redo log是基于innodb存储引擎的，而bin log 是基于数据库服务层实现的，所以mysql数据库中任何存储引擎对数据库进行修改都会产生bin log

  2.作用不同：redo log 用于碰撞恢复(crash recovery),保证**mysql宕机不会影响持久性**；而bin log 用于**时间点恢复数据**(point-in-time-recovery),保证服务器可以基于时间点恢复数据以及**主从复制**

  3.内容不同：redo log是物理日志，内容基于此盘的页；bin log内容是二进制的

  4.写入方式不同：redo log采用**循环写入**的方式，bin log采用**顺序写**的方式

  5.刷盘时机不同:redo log在**事务开始时**即开始写入，而bin log在**事务提交**才写入





## 3. MySQL事务隔离级别详解

### 3.1 定义和作用

- 逻辑上的一组操作，要么都执行，要么都不执行。（比如银行转账）

  ```sql
  start transaction;
  ..
  commit
  ```



### 3.2 事务特性

- 关系型数据库事务都有ACID的特性

  - 原子性：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；

  - 一致性：执行事务前后，数据保持一致，比如A给B转账，A少B多；

  - 持久性：事务成功就持久化到数据库，失败就回滚；

  - 隔离性：事务之间各部影响

    

### 3.3 事务实现原理

以mysql innodb为例

- 通过redo log保证事务的持久性
- 通过undo log保证事务的原子性
- 通过锁机制、mvcc保证事务的隔离性
- binlog保证事务的一致性
- 从而保证一致性



### 3.4 并发事务带来的问题

- 脏读：一个事务访问了另一个事务的未提交的数据

- 丢失修改：一个事务修改了另一个事务未提交数据，导致之前的事务修改操作失败

- 不可重复读：一个事务A在未结束的情况下多次读同一数据，由于其他事务可能会修改数据，导致了A可能读取的数据会不一样

- 幻读：一个事务A读取数据时，另一个事务插入了数据

  > 不可重复度和幻读的区别：不可重复读是发现已有数据的值被修改，幻读是发现记录增多或减少



### 3.5 事务隔离级别

- READ-UNCOMMITTED(读取未提交)

  最低的隔离级别，可能会导致脏读、幻读、不可重复读

- REAS-COMMITTED(读取已提交)

  可以阻止脏读，幻读、不可重复读还会发生

- REPEATABLE-READ(可重复读)

  多次读取结果一致，可以阻止脏读、不可重复读、但还会导致幻读

- SERIALIZABLE(可串性化)

  最高隔离级别，逐个执行，可以阻止脏读、不可重复读、幻读

  |     隔离级别     | 脏读 | 不可重复读 | 幻读 |
  | :--------------: | :--: | :--------: | :--: |
  | READ-UNCOMMITTED |  √   |     √      |  √   |
  |  READ-COMMITTED  |  ×   |     √      |  √   |
  | REPEATABLE-READ  |  ×   |     ×      |  √   |
  |   SERIALIZABLE   |  ×   |     ×      |  ×   |



### 3.6 MySQL默认隔离级别

```sql
-- 查看命令
SELECT @@transaction_isolation;
-- 结果
REPEATABLE-READ（可重读）
```

- 大部分数据库系统的隔离级别是**读取已提交**，但InnoDB默认的**可重复读**并不会有性能损失，其在分布式事务的情况下用到**可串行化**隔离级别。
- Mysql解决幻读的方法：
  - 事务隔离级别调整为SERIALIZABLE
  - 在可重复读的情况下，给事务添加表锁
  - 在可重复读的情况下，给事务添加Next-Key Locks（行锁+间隙锁【对一定范围内的数据进行加锁】）



## 4. SQL语句在MySQL中的执行过程

### 4.1 MySQL基本架构

MySQL主要分为**Server层**和**存储引擎层**

![image-20220418142642796](appendix\1. 数据库_3重要知识点\image-20220418142642796.png)

- **Server 层**：主要包括**连接器**、**查询缓存**、**分析器**、**优化器**、**执行器**等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 `binlog` 日志模块。

- **存储引擎**： **主要负责数据的存储和读取**，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。**

  ![image-20220418183630011](appendix\1. 数据库_3重要知识点\image-20220418183630011.png)

#### 4.1.1 Server层组件

- 连接器

  **身份认证和权限**相关工作（登录MySQL）。进行用户的身份认证，包括校验账户密码。权限等操作。如果用户账户密码已通过，后续只要这个连接不断开，即使管理员修改了该用户的权限，该用户也是不受影响的。

- 查询缓存

  执行查询语句，会先查缓存（8.0版本之后移除了，因为不实用）。缓存所执行的 SELECT 语句以及该语句的结果集。

- 分析器

  词法分析+语法分析。说白了就是看你要干嘛，再检查语法是否正确。

- 优化器

  按照MySQL认为最优的方案执行。比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。

- 执行器

  执行前会**校验该用户**有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。



### 4.2 执行过程

#### 4.2.1 查询（select）

```sql
select * from tb_student  A where A.age='18' and A.name=' 张三 ';
```

- 检查语句是否有权限，没有则返回错误信息，有则查缓存，如果有直接缓存，没有执行下一步
- 通过词法分析，提取sql的关键元素，比如表、列、查询条件；再判断有无语法错误
- 优化器进行确定执行方案，比如先查18还是张三
- 用户权限校验，没有权限返回错误信息，有则调用引擎接口，返回引擎的执行结果



#### 4.2.2 更新（update delete insert）

```sql
update tb_student A set A.age='19' where A.name=' 张三 ';
```

- 先查询张三这条数据，有缓存则用
- 查到查询的语句，将age改为19
- 调用引擎API接口，写入这一行数据。同时记录redo log（prepare），并告诉执行器，执行完成，随时可提交
- 执行器收到通知后记录binlog，然后调用引擎接口，提交事务，提交binlog，提交redo log（commit）
- 更新完成



### 4.3 总结

- 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等

- 查询语句的执行流程如下：

  权限校验（如果命中缓存）--->查询缓存--->分析器--->优化器--->权限校验--->执行器--->引擎

- 更新语句的执行流程如下：

  分析器---->权限校验---->执行器--->引擎-->提交事务--->提交redo log(prepare 状态)--->提交binlog--->提交redo log(commit状态）





## 5. InnoDB存储引擎对MVCC的实现

### 5.1 一致性非锁定读和锁定读

#### 5.1.1 一致性非锁定读

InnoDB通过多版本控制（MVCC）的方式来读取当前执行时间数据库运行的数据。如果读取的行正在执行`delete`、`update`操作，这时读取操作不会因此而会等待行上锁的释放，相反，InnoDB存储引擎会去读取行的一个**快照数据**，通过**undo log 来实现**，这种叫`快照读`。



Read Committed和Repeatable Read中，innodb存储引擎使用默认的一致性非锁定读

Read Committed：被锁定行的最新一份快照数据，每次select都会生成read view

Repeatable Read：读取事务开始时的行数据版本，事务开始后第一次select生成read view



#### 5.1.2 一致性锁定读

如果执行下列语句，锁定读

- `select ... lock in share mode`
- `select ... for update`
- `insert`、`update`、`delete` 操作

在锁定读下，读取的是数据的最新版本，这种读也被称为 `当前读（current read）`。锁定读会对读取到的记录加锁：

`SELECT ... FOR UPDATE`对于读取的行记录加一个**X排它锁**，其他事务不能对锁定的行加任何锁。

`SELECT ... LOCK IN SHARE MODE`对于读取的行记录添加一个**S共享锁**。其它事务可以向被锁定的行加S锁，但是不允许添加X锁，否则会被阻塞。



#### 5.1.3 总结

在一致性非锁定读下，即使读取的记录已被其它事务加上 `X` 锁，这时记录也是可以被读取的，即读取的快照数据。上面说了，在 `Repeatable Read` 下 `MVCC` 防止了部分幻读，这边的 “部分” 是指在 `一致性非锁定读` 情况下，只能读取到第一次查询之前所插入的数据（根据 Read View 判断数据可见性，Read View 在第一次查询时生成）。

如果是 `当前读` ，每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。所以， **`InnoDB` 在实现`Repeatable Read` 时，如果执行的是当前读，则会对读取的记录使用 `Next-key Lock` ，来防止其它事务在间隙间插入数据**





### 5.2 InnoDB对MVCC的实现

**MVCC只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。**其他两个隔离级别都和MVCC不兼容，因为READ UNCOMMITED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。



`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。

undo log :

实现 `MVCC` ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 `undo log` 读取之前的版本数据，以此实现**非锁定读**。



数据可见性算法：

在 `InnoDB` 存储引擎中，创建一个新事务后，执行每个 `select` 语句前，都会创建一个快照（Read View），**快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号**。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）



### 5.3 MVCC解决不可重复读

**在 RC 隔离级别下，事务在每次查询开始时都会生成并设置新的 Read View，所以导致不可重复读**



### 5.4 MVCC + Next-key-Lock 防止幻读

`InnoDB`存储引擎在 **RR 级别**下通过 `MVCC`和 `Next-key Lock` 来解决幻读问题:

- **执行普通 `select`，此时会以 `MVCC` 快照读的方式读取数据**

- **执行 select...for update/lock in share mode、insert、update、delete 等当前读**

  在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读。`InnoDB` 使用 [Next-key Lock](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-next-key-locks) 来防止这种情况。当执行当前读时，**会锁定读取到的记录的同时，锁定它们的间隙**，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读。



## 6. MySQL中的隐式转换造成的索引失效

数据库优化是一个任重而道远的任务，想要做优化必须深入理解数据库的各种特性。于数据库层面，最常见的恐怕就是索引失效了，且一开始因为数据量小还不易被发现。本文讲得是**隐式转换造成的索引失效**。



### 6.1 测试

```sql
1: SELECT * FROM `test1` WHERE num1 = 10000;
2: SELECT * FROM `test1` WHERE num1 = '10000';
3: SELECT * FROM `test1` WHERE num2 = 10000;
4: SELECT * FROM `test1` WHERE num2 = '10000';
```

表共1000 万条数据，其中`num1`是`int`,`num2`是`varchar`



### 6.2 执行结果

其中 124 三条 SQL 基本都是瞬间出结果，但是第三条 SQL，多次测试耗时基本在 4.5~4.8 秒之间。



### 6.3 结果分析

- 查看执行计划数据

  ![image-20220418194002743](appendix\1. 数据库_3重要知识点\image-20220418194002743.png)

  124 三条 SQL 都能使用到索引，连接类型都为`ref`，扫描行数都为 1，所以效率非常高。再看看第三条 SQL，没有用上索引，所以为全表扫描，`rows`直接到达 1000 万了，所以性能差别才那么大。

- 结果分析

  当操作符与不同类型的操作数一起使用时，会发生类型转换以使操作数兼容。

  2.3两条发生隐式转换，左右两边都会转换为浮点数再进行比较，左边是带索引的

  ```sql
  第2条：(int-varchar) 。左边int转换为浮点数还是`10000`，右边varchar`'10000'`，转换为浮点数也是`10000`。两边的转换结果都是**唯一确定**的，所以不影响使用索引。
  
  第3条：(varchar-int) 。左边varchar转为浮点数`10000`，但不唯一，因为`10000a`,`010000`,`10000`都会转为浮点数`10000`，所以索引失效了。
  ```



### 6.4 总结

- 当操作符**左右两边的数据类型不一致**时，会发生**隐式转换**
- 当 where 查询操作符**左边为数值类型**时发生了隐式转换，那么对效率影响不大，但还是不推荐这么做。
- 当 where 查询操作符**左边为字符类型**时发生了隐式转换，那么会导致索引失效，造成全表扫描效率极低。
- 字符串转换为数值类型时，非数字开头的字符串会转化为`0`，以数字开头的字符串会截取从第一个字符到第一个非数字内容为止的值为转化结果。
